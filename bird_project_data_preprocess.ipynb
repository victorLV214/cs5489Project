{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8d6dd2",
   "metadata": {
    "papermill": {
     "duration": 0.002284,
     "end_time": "2025-04-14T13:45:53.973091",
     "exception": false,
     "start_time": "2025-04-14T13:45:53.970807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bird Project Data Preprocessing (In Kaggle Env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab329620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "from scipy import signal\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1634828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T13:45:53.978863Z",
     "iopub.status.busy": "2025-04-14T13:45:53.978446Z",
     "iopub.status.idle": "2025-04-14T13:46:16.278049Z",
     "shell.execute_reply": "2025-04-14T13:46:16.273022Z"
    },
    "papermill": {
     "duration": 22.306507,
     "end_time": "2025-04-14T13:46:16.281638",
     "exception": false,
     "start_time": "2025-04-14T13:45:53.975131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyAudioConfig:\n",
    "    def __init__(self):\n",
    "        # sampling\n",
    "        self.sample_rate = 32000\n",
    "        self.window_size = 5  # seconds\n",
    "\n",
    "        # mel-spec\n",
    "        self.n_fft = 2048\n",
    "        self.hop_length = 512\n",
    "        self.n_mels = 128\n",
    "        self.fmin = 20\n",
    "        self.fmax = 16000\n",
    "        self.power = 2.0\n",
    "        self.target_shape = (256, 128)\n",
    "\n",
    "        # processing\n",
    "        self.noise_reduction_strength = 0.1\n",
    "        self.contrast_factor = 0.15\n",
    "\n",
    "        # spec augment\n",
    "        self.freq_mask_param = 20\n",
    "        self.time_mask_param = 30\n",
    "        self.freq_mask_count = 1\n",
    "        self.time_mask_count = 1\n",
    "\n",
    "        self.eps = 1e-6\n",
    "\n",
    "\n",
    "class MyAudioPipeline:\n",
    "    def __init__(self, cfg: MyAudioConfig):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def reduce_noise(self, audio: np.ndarray) -> np.ndarray:\n",
    "        denoised = signal.medfilt(audio, 5)\n",
    "        a = self.cfg.noise_reduction_strength\n",
    "        return (1 - a) * audio + a * denoised\n",
    "\n",
    "    def normalize_audio(self, audio: np.ndarray) -> np.ndarray:\n",
    "        audio = audio - np.mean(audio)\n",
    "        m = np.max(np.abs(audio))\n",
    "        return audio / m if m > 0 else audio\n",
    "\n",
    "    def enhance_contrast(self, spec: np.ndarray) -> np.ndarray:\n",
    "        mu = np.mean(spec)\n",
    "        return np.clip(mu + (spec - mu) * (1 + self.cfg.contrast_factor), 0, 1)\n",
    "\n",
    "    def spec_augment(self, spec: np.ndarray) -> np.ndarray:\n",
    "        out = spec.copy()\n",
    "        # freq mask\n",
    "        for _ in range(self.cfg.freq_mask_count):\n",
    "            f = np.random.randint(0, self.cfg.freq_mask_param)\n",
    "            f0 = np.random.randint(0, out.shape[0] - f)\n",
    "            out[f0:f0 + f, :] = 0\n",
    "        # time mask\n",
    "        for _ in range(self.cfg.time_mask_count):\n",
    "            t = np.random.randint(0, self.cfg.time_mask_param)\n",
    "            t0 = np.random.randint(0, out.shape[1] - t)\n",
    "            out[:, t0:t0 + t] = 0\n",
    "        return out\n",
    "\n",
    "    def audio_to_melspec(self, audio: np.ndarray) -> np.ndarray:\n",
    "        # pad/trim\n",
    "        n_samples = self.cfg.sample_rate * self.cfg.window_size\n",
    "        if len(audio) < n_samples:\n",
    "            audio = np.pad(audio, (0, n_samples - len(audio)))\n",
    "        else:\n",
    "            audio = audio[:n_samples]\n",
    "\n",
    "        audio = self.normalize_audio(self.reduce_noise(audio))\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(\n",
    "            y=audio,\n",
    "            sr=self.cfg.sample_rate,\n",
    "            n_fft=self.cfg.n_fft,\n",
    "            hop_length=self.cfg.hop_length,\n",
    "            n_mels=self.cfg.n_mels,\n",
    "            fmin=self.cfg.fmin,\n",
    "            fmax=self.cfg.fmax,\n",
    "            power=self.cfg.power,\n",
    "        )\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + self.cfg.eps)\n",
    "\n",
    "        mel_norm = self.enhance_contrast(mel_norm)\n",
    "        mel_norm = self.spec_augment(mel_norm)\n",
    "\n",
    "        if self.cfg.target_shape:\n",
    "            mel_norm = cv2.resize(mel_norm, self.cfg.target_shape, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        return mel_norm.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376aadc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T13:46:16.295296Z",
     "iopub.status.busy": "2025-04-14T13:46:16.294561Z",
     "iopub.status.idle": "2025-04-14T14:25:16.946970Z",
     "shell.execute_reply": "2025-04-14T14:25:16.945430Z"
    },
    "papermill": {
     "duration": 2341.46309,
     "end_time": "2025-04-14T14:25:17.752505",
     "exception": false,
     "start_time": "2025-04-14T13:46:16.289415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28564 ogg files under /kaggle/input/birdclef-2025/train_audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28564/28564 [38:08<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to train_data.npy\n"
     ]
    }
   ],
   "source": [
    "cfg = MyAudioConfig()\n",
    "pipeline = MyAudioPipeline(cfg)\n",
    "\n",
    "train_audio_dir = '/kaggle/input/birdclef-2025/train_audio'\n",
    "output_file = 'train_data.npy'\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "ogg_files = glob.glob(os.path.join(train_audio_dir, '**', '*.ogg'), recursive=True)\n",
    "print(f\"Found {len(ogg_files)} ogg files under {train_audio_dir}\")\n",
    "\n",
    "for oggfile in tqdm(ogg_files):\n",
    "    label_dir = os.path.basename(os.path.dirname(oggfile))\n",
    "    label = label_dir \n",
    "    filename = os.path.basename(oggfile)\n",
    "    \n",
    "    y, sr = librosa.load(oggfile, sr=cfg.sample_rate, mono=True)\n",
    "    \n",
    "    mel_spec = pipeline.audio_to_melspec(y)\n",
    "    \n",
    "    file_id = f\"{label}_{filename}\"\n",
    "    data_dict[file_id] = {\n",
    "        \"data\": mel_spec,\n",
    "        \"label\": label\n",
    "    }\n",
    "\n",
    "np.save(output_file, data_dict, allow_pickle=True)\n",
    "print(f\"Saved processed data to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2372.55083,
   "end_time": "2025-04-14T14:25:21.536883",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-14T13:45:48.986053",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
