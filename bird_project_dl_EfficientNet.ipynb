{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd37801",
   "metadata": {},
   "source": [
    "# Deep learning algorithms to classify audio (EfficientNet B2 + Two-stage fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f97ba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "['DTypePolicy', 'FloatDTypePolicy', 'Function', 'Initializer', 'Input', 'InputSpec', 'KerasTensor', 'Layer', 'Loss', 'Metric', 'Model', 'Operation', 'Optimizer', 'Quantizer', 'Regularizer', 'RematScope', 'Sequential', 'StatelessScope', 'SymbolicScope', 'Variable', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'activations', 'applications', 'backend', 'callbacks', 'config', 'constraints', 'datasets', 'device', 'distribution', 'dtype_policies', 'export', 'initializers', 'layers', 'legacy', 'losses', 'metrics', 'mixed_precision', 'models', 'name_scope', 'ops', 'optimizers', 'preprocessing', 'quantizers', 'random', 'regularizers', 'remat', 'tree', 'utils', 'version', 'visualization', 'wrappers']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB2, ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "print(tf.__version__)\n",
    "print(dir(tf.keras))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e9807",
   "metadata": {},
   "source": [
    "## BirdCLEF 2025: EfficientNet B2 + Two-stage fine-tuning Multi-label Classification Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741cdeec",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "To improve model performance beyond the ResNet50 baseline, we introduced **EfficientNet B2** as the feature extractor. EfficientNet models are known for their compound scaling of depth, width, and resolution, offering higher performance with fewer parameters.\n",
    "\n",
    "Instead of training the entire network from scratch, we adopt a **two-stage fine-tuning strategy** to leverage pretrained weights from ImageNet and prevent overfitting on our limited dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Stage 1: Freeze the base model\n",
    "\n",
    "- Load `EfficientNetB2` with `weights='imagenet'` and `include_top=False`\n",
    "- **Freeze all layers** in the base model (i.e., `base_model.trainable = False`)\n",
    "- Only train the **newly added top layers**:\n",
    "  - GlobalAveragePooling → Dropout → Dense(206, activation='sigmoid')\n",
    "- Use `BinaryCrossentropy` with `label_smoothing` to stabilize training\n",
    "\n",
    "### Stage 2: Unfreeze and fine-tune\n",
    "\n",
    "- After the top layers are warm-started, **unfreeze the last N layers** of EfficientNet\n",
    "- Recompile the model with a **lower learning rate** (e.g., 1e-5)\n",
    "- Continue training for another 5–10 epochs\n",
    "\n",
    "---\n",
    "\n",
    "### Why EfficientNet B2?\n",
    "\n",
    "| Model       | Params | Accuracy | Speed | Notes                |\n",
    "|-------------|--------|----------|-------|----------------------|\n",
    "| ResNet50    | 24M    | High     | OK    | Strong baseline      |\n",
    "| **EffNetB2**| 8M     | High+    | Fast  | Higher AUC with less |\n",
    "| EffNetB3    | 12M    | Higher   | Slower| GPU memory ↑         |\n",
    "\n",
    "EfficientNet-B2 offers **better performance-per-parameter ratio** than ResNet50, making it a solid upgrade path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26adc42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 28564\n",
      "Mel shape: (128,256)\n",
      "Number of unique species: 206\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 1) Load train_data.npy\n",
    "# -------------------------\n",
    "# Content example:\n",
    "# data_dict[fid] = {\n",
    "# 'data': (128,256) Mel spectrum,\n",
    "# 'label': 'Name of a species'\n",
    "# }\n",
    "# -------------------------\n",
    "data_dict = np.load('dataset/train_data.npy', allow_pickle=True).item()\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "all_labels_set = set()\n",
    "\n",
    "for fid, content in data_dict.items():\n",
    "    mel_2d = content['data']             # shape=(128,256)\n",
    "    label_str = content['label']         # 'species_xxx'\n",
    "\n",
    "    X_list.append(mel_2d)\n",
    "    y_list.append(label_str)\n",
    "    all_labels_set.add(label_str)\n",
    "\n",
    "X_array = np.array(X_list, dtype=np.float32)    # shape=(N,128,256)\n",
    "y_array = np.array(y_list)                      # shape=(N,)\n",
    "\n",
    "all_labels = sorted(list(all_labels_set))\n",
    "label_to_idx = {lb: i for i, lb in enumerate(all_labels)}\n",
    "num_species = len(all_labels)\n",
    "\n",
    "print(\"Number of samples:\", X_array.shape[0])\n",
    "print(\"Mel shape: (128,256)\")\n",
    "print(\"Number of unique species:\", num_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62fcec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (22851, 128, 256) (22851, 206)\n",
      "Val shape: (5713, 128, 256) (5713, 206)\n",
      "Global Mel range in X_array:\n",
      "  min = 0.0 , max = 1.0\n",
      "Train Mel range:\n",
      "  min = 0.0 , max = 1.0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2) Multi-label One-Hot: Only one position in each record is 1\n",
    "# -----------------------------\n",
    "Y_one_hot = np.zeros((len(y_array), num_species), dtype=np.float32)\n",
    "for i, lb in enumerate(y_array):\n",
    "    Y_one_hot[i, label_to_idx[lb]] = 1.0\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Split training/validation set (80/20)\n",
    "# -----------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_array, Y_one_hot, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_array # Stratify by string label\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Val shape:\",   X_val.shape,   y_val.shape)\n",
    "\n",
    "print(\"Global Mel range in X_array:\")\n",
    "print(\"  min =\", X_array.min(), \", max =\", X_array.max())\n",
    "print(\"Train Mel range:\")\n",
    "print(\"  min =\", X_train.min(), \", max =\", X_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc129c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weight example: [(110, 7.7952755905511815), (177, 6.470588235294118), (71, 3.1832797427652735), (30, 33.0), (47, 47.142857142857146)]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4) Dealing with data imbalance -> class_weight\n",
    "# Since each record has only one label, we can count the number of times each label appears\n",
    "# and assign values ​​in reverse proportion.\n",
    "# -----------------------------\n",
    "label_counts = Counter(y_array)\n",
    "max_count = max(label_counts.values())\n",
    "# Give higher weight to less common categories\n",
    "class_weight = {}\n",
    "for lb, freq in label_counts.items():\n",
    "    idx = label_to_idx[lb]\n",
    "    class_weight[idx] = max_count / freq\n",
    "\n",
    "print(\"Class weight example:\", list(class_weight.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaec645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5) Build data pipeline + data augmentation\n",
    "# Random flip/rotate (for images)\n",
    "# -----------------------------\n",
    "augment_layers = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(height_factor=0.05)\n",
    "])\n",
    "\n",
    "\n",
    "def preprocess_fn(x, y, training=True):\n",
    "    x = tf.expand_dims(x, -1)            # (128,256,1)\n",
    "    x = tf.image.grayscale_to_rgb(x)     # (128,256,3)\n",
    "    x = preprocess_input(x * 255.0)     \n",
    "    if training:\n",
    "        x = augment_layers(x, training=True)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_ds = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "            .shuffle(2048)\n",
    "            .map(lambda x, y: preprocess_fn(x, y, True))\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "val_ds = (tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "            .map(lambda x, y: preprocess_fn(x, y, False))\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "207a2faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EffNetB2_BirdCLEF\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"EffNetB2_BirdCLEF\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,768,569</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">290,254</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb2 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1408\u001b[0m)     │     \u001b[38;5;34m7,768,569\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │         \u001b[38;5;34m5,632\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m206\u001b[0m)            │       \u001b[38;5;34m290,254\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,064,455</span> (30.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,064,455\u001b[0m (30.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">293,070</span> (1.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m293,070\u001b[0m (1.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,771,385</span> (29.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,771,385\u001b[0m (29.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6) Build effnet_b2 (Keras)\n",
    "# -----------------------------\n",
    "def build_effnet_b2(input_shape=(128,256,3), num_classes=206):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    base = EfficientNetB2(include_top=False, weights='imagenet')\n",
    "    base.trainable = False                          # stage‑1 \n",
    "    x = base(inp, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    return models.Model(inp, out, name='EffNetB2_BirdCLEF')\n",
    "\n",
    "\n",
    "model = build_effnet_b2(num_classes=num_species)\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0  # Smoothing\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.AUC(name='auc', multi_label=True),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(optimizer=Adam(3e-4), loss=loss_fn, metrics=metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Early Stop Callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3df13df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 515ms/step - auc: 0.4591 - loss: 1.1254 - precision: 0.0054 - recall: 0.0323 - val_auc: 0.4593 - val_loss: 0.2789 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 750ms/step - auc: 0.4589 - loss: 0.3202 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.4699 - val_loss: 0.1960 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 991ms/step - auc: 0.4622 - loss: 0.2677 - precision: 0.0015 - recall: 2.1861e-06 - val_auc: 0.4822 - val_loss: 0.1542 - val_precision: 0.0417 - val_recall: 1.7504e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 449ms/step - auc: 0.4777 - loss: 0.2492 - precision: 0.0636 - recall: 1.2172e-04 - val_auc: 0.4961 - val_loss: 0.1159 - val_precision: 0.0588 - val_recall: 3.5008e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 457ms/step - auc: 0.4867 - loss: 0.2492 - precision: 0.0855 - recall: 1.6498e-04 - val_auc: 0.5121 - val_loss: 0.0991 - val_precision: 0.0190 - val_recall: 5.2512e-04 - learning_rate: 3.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 474ms/step - auc: 0.4922 - loss: 0.2389 - precision: 0.0708 - recall: 2.6647e-04 - val_auc: 0.5165 - val_loss: 0.0970 - val_precision: 0.0682 - val_recall: 0.0011 - learning_rate: 3.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 468ms/step - auc: 0.4864 - loss: 0.2423 - precision: 0.0340 - recall: 1.0555e-04 - val_auc: 0.5318 - val_loss: 0.0886 - val_precision: 0.1169 - val_recall: 0.0016 - learning_rate: 3.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 473ms/step - auc: 0.5060 - loss: 0.2350 - precision: 0.0834 - recall: 2.9968e-04 - val_auc: 0.5397 - val_loss: 0.0846 - val_precision: 0.0957 - val_recall: 0.0019 - learning_rate: 3.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 418ms/step - auc: 0.4942 - loss: 0.2399 - precision: 0.1238 - recall: 4.4965e-04 - val_auc: 0.5516 - val_loss: 0.0757 - val_precision: 0.0429 - val_recall: 0.0011 - learning_rate: 3.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 410ms/step - auc: 0.5012 - loss: 0.2346 - precision: 0.1155 - recall: 4.6875e-04 - val_auc: 0.5551 - val_loss: 0.0762 - val_precision: 0.1200 - val_recall: 0.0016 - learning_rate: 3.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 404ms/step - auc: 0.5095 - loss: 0.2315 - precision: 0.0983 - recall: 3.6466e-04 - val_auc: 0.5656 - val_loss: 0.0726 - val_precision: 0.0552 - val_recall: 0.0018 - learning_rate: 3.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 412ms/step - auc: 0.5126 - loss: 0.2336 - precision: 0.0741 - recall: 4.6260e-04 - val_auc: 0.5671 - val_loss: 0.0678 - val_precision: 0.0787 - val_recall: 0.0018 - learning_rate: 3.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 419ms/step - auc: 0.5107 - loss: 0.2367 - precision: 0.1383 - recall: 8.0661e-04 - val_auc: 0.5717 - val_loss: 0.0695 - val_precision: 0.0741 - val_recall: 0.0018 - learning_rate: 3.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 414ms/step - auc: 0.5095 - loss: 0.2331 - precision: 0.1183 - recall: 5.8961e-04 - val_auc: 0.5756 - val_loss: 0.0675 - val_precision: 0.0787 - val_recall: 0.0018 - learning_rate: 3.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 412ms/step - auc: 0.5136 - loss: 0.2312 - precision: 0.0781 - recall: 3.7676e-04 - val_auc: 0.5765 - val_loss: 0.0648 - val_precision: 0.0909 - val_recall: 0.0014 - learning_rate: 3.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 416ms/step - auc: 0.5151 - loss: 0.2283 - precision: 0.1275 - recall: 8.2885e-04 - val_auc: 0.5837 - val_loss: 0.0648 - val_precision: 0.0654 - val_recall: 0.0018 - learning_rate: 3.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 420ms/step - auc: 0.5183 - loss: 0.2328 - precision: 0.1659 - recall: 9.4437e-04 - val_auc: 0.5885 - val_loss: 0.0611 - val_precision: 0.0566 - val_recall: 0.0016 - learning_rate: 3.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 427ms/step - auc: 0.5177 - loss: 0.2344 - precision: 0.0750 - recall: 5.0856e-04 - val_auc: 0.5827 - val_loss: 0.0627 - val_precision: 0.1143 - val_recall: 0.0021 - learning_rate: 3.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 424ms/step - auc: 0.5156 - loss: 0.2307 - precision: 0.1625 - recall: 8.1565e-04 - val_auc: 0.5905 - val_loss: 0.0599 - val_precision: 0.0815 - val_recall: 0.0026 - learning_rate: 3.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 427ms/step - auc: 0.5227 - loss: 0.2258 - precision: 0.1628 - recall: 9.4571e-04 - val_auc: 0.5880 - val_loss: 0.0585 - val_precision: 0.0924 - val_recall: 0.0019 - learning_rate: 3.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# stage 1\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    class_weight=class_weight \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbbffaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 665ms/step - auc: 0.5184 - loss: 0.0364 - precision: 0.0906 - recall: 7.7586e-04 - val_auc: 0.5526 - val_loss: 0.0311 - val_precision: 0.2475 - val_recall: 0.0044 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 588ms/step - auc: 0.5011 - loss: 0.0317 - precision: 0.1855 - recall: 9.6353e-04 - val_auc: 0.5996 - val_loss: 0.0282 - val_precision: 0.2421 - val_recall: 0.0135 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 588ms/step - auc: 0.5159 - loss: 0.0301 - precision: 0.1994 - recall: 0.0027 - val_auc: 0.6143 - val_loss: 0.0272 - val_precision: 0.2767 - val_recall: 0.0222 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 593ms/step - auc: 0.5231 - loss: 0.0295 - precision: 0.2640 - recall: 0.0038 - val_auc: 0.6282 - val_loss: 0.0268 - val_precision: 0.3174 - val_recall: 0.0243 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 595ms/step - auc: 0.5325 - loss: 0.0289 - precision: 0.3301 - recall: 0.0057 - val_auc: 0.6273 - val_loss: 0.0261 - val_precision: 0.3543 - val_recall: 0.0266 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 592ms/step - auc: 0.5419 - loss: 0.0284 - precision: 0.3108 - recall: 0.0056 - val_auc: 0.6298 - val_loss: 0.0258 - val_precision: 0.3345 - val_recall: 0.0322 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 590ms/step - auc: 0.5496 - loss: 0.0282 - precision: 0.3090 - recall: 0.0064 - val_auc: 0.6315 - val_loss: 0.0254 - val_precision: 0.3876 - val_recall: 0.0284 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 603ms/step - auc: 0.5529 - loss: 0.0278 - precision: 0.3151 - recall: 0.0065 - val_auc: 0.6258 - val_loss: 0.0252 - val_precision: 0.3876 - val_recall: 0.0338 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 597ms/step - auc: 0.5608 - loss: 0.0275 - precision: 0.3058 - recall: 0.0066 - val_auc: 0.6321 - val_loss: 0.0247 - val_precision: 0.4260 - val_recall: 0.0327 - learning_rate: 1.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 606ms/step - auc: 0.5663 - loss: 0.0275 - precision: 0.4099 - recall: 0.0095 - val_auc: 0.6453 - val_loss: 0.0245 - val_precision: 0.4800 - val_recall: 0.0315 - learning_rate: 1.0000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 600ms/step - auc: 0.5761 - loss: 0.0271 - precision: 0.3456 - recall: 0.0078 - val_auc: 0.6517 - val_loss: 0.0243 - val_precision: 0.4706 - val_recall: 0.0336 - learning_rate: 1.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 616ms/step - auc: 0.5742 - loss: 0.0269 - precision: 0.4346 - recall: 0.0101 - val_auc: 0.6487 - val_loss: 0.0242 - val_precision: 0.4664 - val_recall: 0.0401 - learning_rate: 1.0000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 612ms/step - auc: 0.5810 - loss: 0.0268 - precision: 0.4189 - recall: 0.0118 - val_auc: 0.6408 - val_loss: 0.0240 - val_precision: 0.5103 - val_recall: 0.0389 - learning_rate: 1.0000e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 619ms/step - auc: 0.5879 - loss: 0.0266 - precision: 0.4067 - recall: 0.0112 - val_auc: 0.6567 - val_loss: 0.0241 - val_precision: 0.5176 - val_recall: 0.0438 - learning_rate: 1.0000e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 623ms/step - auc: 0.5862 - loss: 0.0264 - precision: 0.3985 - recall: 0.0105 - val_auc: 0.6534 - val_loss: 0.0239 - val_precision: 0.5414 - val_recall: 0.0446 - learning_rate: 1.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 609ms/step - auc: 0.5938 - loss: 0.0262 - precision: 0.4281 - recall: 0.0129 - val_auc: 0.6657 - val_loss: 0.0235 - val_precision: 0.5496 - val_recall: 0.0446 - learning_rate: 1.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 620ms/step - auc: 0.5986 - loss: 0.0262 - precision: 0.4688 - recall: 0.0137 - val_auc: 0.6652 - val_loss: 0.0236 - val_precision: 0.5274 - val_recall: 0.0506 - learning_rate: 1.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 624ms/step - auc: 0.6023 - loss: 0.0260 - precision: 0.4846 - recall: 0.0146 - val_auc: 0.6644 - val_loss: 0.0233 - val_precision: 0.5583 - val_recall: 0.0511 - learning_rate: 1.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 628ms/step - auc: 0.6072 - loss: 0.0258 - precision: 0.4572 - recall: 0.0152 - val_auc: 0.6674 - val_loss: 0.0232 - val_precision: 0.5792 - val_recall: 0.0506 - learning_rate: 1.0000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 649ms/step - auc: 0.6154 - loss: 0.0256 - precision: 0.4755 - recall: 0.0153 - val_auc: 0.6667 - val_loss: 0.0230 - val_precision: 0.5754 - val_recall: 0.0541 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# stage 2\n",
    "gc.collect()\n",
    "for layer in model.get_layer('efficientnetb2').layers[-100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(1e-5), loss=loss_fn, metrics=metrics)\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "model.save(\"effnetb2_two_stage.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74558628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 352ms/step - auc: 0.5990 - loss: 0.0230 - precision: 0.5784 - recall: 0.0539\n",
      "Validation Loss: 0.0230\n",
      "Validation AUC: 0.6667\n",
      "Precision: 0.5754\n",
      "Recall: 0.0541\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(val_ds, verbose=1)\n",
    "val_loss = results[0]\n",
    "val_auc = results[1]\n",
    "val_precision = results[2]\n",
    "val_recall = results[3]\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall: {val_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
