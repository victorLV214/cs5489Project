{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd37801",
   "metadata": {},
   "source": [
    "# Deep learning algorithms to classify audio (EfficientNet B2 + Two-stage fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f97ba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "['DTypePolicy', 'FloatDTypePolicy', 'Function', 'Initializer', 'Input', 'InputSpec', 'KerasTensor', 'Layer', 'Loss', 'Metric', 'Model', 'Operation', 'Optimizer', 'Quantizer', 'Regularizer', 'RematScope', 'Sequential', 'StatelessScope', 'SymbolicScope', 'Variable', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'activations', 'applications', 'backend', 'callbacks', 'config', 'constraints', 'datasets', 'device', 'distribution', 'dtype_policies', 'export', 'initializers', 'layers', 'legacy', 'losses', 'metrics', 'mixed_precision', 'models', 'name_scope', 'ops', 'optimizers', 'preprocessing', 'quantizers', 'random', 'regularizers', 'remat', 'tree', 'utils', 'version', 'visualization', 'wrappers']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB2, ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "print(tf.__version__)\n",
    "print(dir(tf.keras))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e9807",
   "metadata": {},
   "source": [
    "## BirdCLEF 2025: EfficientNet B2 + Two-stage fine-tuning Multi-label Classification Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741cdeec",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "To improve model performance beyond the ResNet50 baseline, we introduced **EfficientNet B2** as the feature extractor. EfficientNet models are known for their compound scaling of depth, width, and resolution, offering higher performance with fewer parameters.\n",
    "\n",
    "Instead of training the entire network from scratch, we adopt a **two-stage fine-tuning strategy** to leverage pretrained weights from ImageNet and prevent overfitting on our limited dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Stage 1: Freeze the base model\n",
    "\n",
    "- Load `EfficientNetB2` with `weights='imagenet'` and `include_top=False`\n",
    "- **Freeze all layers** in the base model (i.e., `base_model.trainable = False`)\n",
    "- Only train the **newly added top layers**:\n",
    "  - GlobalAveragePooling → Dropout → Dense(206, activation='sigmoid')\n",
    "- Use `BinaryCrossentropy` with `label_smoothing` to stabilize training\n",
    "\n",
    "### Stage 2: Unfreeze and fine-tune\n",
    "\n",
    "- After the top layers are warm-started, **unfreeze the last N layers** of EfficientNet\n",
    "- Recompile the model with a **lower learning rate** (e.g., 1e-5)\n",
    "- Continue training for another 5–10 epochs\n",
    "\n",
    "---\n",
    "\n",
    "### Why EfficientNet B2?\n",
    "\n",
    "| Model       | Params | Accuracy | Speed | Notes                |\n",
    "|-------------|--------|----------|-------|----------------------|\n",
    "| ResNet50    | 24M    | High     | OK    | Strong baseline      |\n",
    "| **EffNetB2**| 8M     | High+    | Fast  | Higher AUC with less |\n",
    "| EffNetB3    | 12M    | Higher   | Slower| GPU memory ↑         |\n",
    "\n",
    "EfficientNet-B2 offers **better performance-per-parameter ratio** than ResNet50, making it a solid upgrade path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26adc42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 28564\n",
      "Mel shape: (128,256)\n",
      "Number of unique species: 206\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 1) Load train_data.npy\n",
    "# -------------------------\n",
    "# Content example:\n",
    "# data_dict[fid] = {\n",
    "# 'data': (128,256) Mel spectrum,\n",
    "# 'label': 'Name of a species'\n",
    "# }\n",
    "# -------------------------\n",
    "data_dict = np.load('dataset/train_data.npy', allow_pickle=True).item()\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "all_labels_set = set()\n",
    "\n",
    "for fid, content in data_dict.items():\n",
    "    mel_2d = content['data']             # shape=(128,256)\n",
    "    label_str = content['label']         # 'species_xxx'\n",
    "\n",
    "    X_list.append(mel_2d)\n",
    "    y_list.append(label_str)\n",
    "    all_labels_set.add(label_str)\n",
    "\n",
    "X_array = np.array(X_list, dtype=np.float32)    # shape=(N,128,256)\n",
    "y_array = np.array(y_list)                      # shape=(N,)\n",
    "\n",
    "all_labels = sorted(list(all_labels_set))\n",
    "label_to_idx = {lb: i for i, lb in enumerate(all_labels)}\n",
    "num_species = len(all_labels)\n",
    "\n",
    "print(\"Number of samples:\", X_array.shape[0])\n",
    "print(\"Mel shape: (128,256)\")\n",
    "print(\"Number of unique species:\", num_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fcec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (22851, 128, 256) (22851, 206)\n",
      "Val shape: (5713, 128, 256) (5713, 206)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2) Multi-label One-Hot: Only one position in each record is 1\n",
    "# -----------------------------\n",
    "Y_one_hot = np.zeros((len(y_array), num_species), dtype=np.float32)\n",
    "for i, lb in enumerate(y_array):\n",
    "    Y_one_hot[i, label_to_idx[lb]] = 1.0\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Split training/validation set (80/20)\n",
    "# -----------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_array, Y_one_hot, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_array # Stratify by string label\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Val shape:\",   X_val.shape,   y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc129c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weight example: [(110, 7.7952755905511815), (177, 6.470588235294118), (71, 3.1832797427652735), (30, 33.0), (47, 47.142857142857146)]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4) Dealing with data imbalance -> class_weight\n",
    "# Since each record has only one label, we can count the number of times each label appears\n",
    "# and assign values ​​in reverse proportion.\n",
    "# -----------------------------\n",
    "label_counts = Counter(y_array)\n",
    "max_count = max(label_counts.values())\n",
    "# Give higher weight to less common categories\n",
    "class_weight = {}\n",
    "for lb, freq in label_counts.items():\n",
    "    idx = label_to_idx[lb]\n",
    "    class_weight[idx] = max_count / freq\n",
    "\n",
    "print(\"Class weight example:\", list(class_weight.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcaec645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5) Build data pipeline + data augmentation\n",
    "# Random flip/rotate (for images)\n",
    "# -----------------------------\n",
    "augment_layers = tf.keras.Sequential([\n",
    "    layers.RandomFlip(mode='horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "def preprocess_fn(x, y):\n",
    "    # x: (128,256) => expand dims到(128,256,1)\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    # cast to float\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = augment_layers(x, training=True)  \n",
    "    return x, y\n",
    "\n",
    "def preprocess_fn_val(x, y):\n",
    "    # No data augmentation for validation set\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    return x, y\n",
    "\n",
    "batch_size = 16\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.shuffle(buffer_size=2048).map(preprocess_fn).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_ds = val_ds.map(preprocess_fn_val).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207a2faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EffNetB2_BirdCLEF\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"EffNetB2_BirdCLEF\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,768,569</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">290,254</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb2 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1408\u001b[0m)     │     \u001b[38;5;34m7,768,569\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m206\u001b[0m)            │       \u001b[38;5;34m290,254\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,058,829</span> (30.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,058,829\u001b[0m (30.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">290,260</span> (1.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m290,260\u001b[0m (1.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,768,569</span> (29.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,768,569\u001b[0m (29.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6) Build effnet_b2 (Keras)\n",
    "# -----------------------------\n",
    "def build_effnet_b2(input_shape=(128, 256, 1), num_classes=206, drop_rate=0.3):\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(3, (1, 1), padding='same')(inp)\n",
    "\n",
    "    base = EfficientNetB2(\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    x = base(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(drop_rate)(x)\n",
    "    out = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    return models.Model(inp, out, name=\"EffNetB2_BirdCLEF\")\n",
    "\n",
    "\n",
    "model = build_effnet_b2()\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.05  # Smoothing\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.AUC(name='auc', multi_label=True),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), loss=loss_fn, metrics=metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Early Stop Callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df13df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m  75/1429\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:40\u001b[0m 251ms/step - auc: 0.3081 - loss: 0.5761 - precision: 0.0057 - recall: 0.2421"
     ]
    }
   ],
   "source": [
    "# stage 1\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbffaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage 2\n",
    "for layer in model.get_layer('efficientnetb2').layers[-100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(1e-5), loss=loss_fn, metrics=metrics)\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "model.save(\"effnetb2_two_stage.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74558628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 150ms/step - auc: 0.7709 - loss: 0.1266 - precision: 0.7917 - recall: 0.3850\n",
      "Validation Loss: 0.1266\n",
      "Validation AUC: 0.8828\n",
      "Precision: 0.7959\n",
      "Recall: 0.3898\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(val_ds, verbose=1)\n",
    "val_loss = results[0]\n",
    "val_auc = results[1]\n",
    "val_precision = results[2]\n",
    "val_recall = results[3]\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall: {val_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
