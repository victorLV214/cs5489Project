{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd37801",
   "metadata": {},
   "source": [
    "# Deep learning algorithms to classify audio (ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c065b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: keras in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (3.9.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from keras) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\ab-in\\appdata\\roaming\\python\\python310\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.22.0-cp310-cp310-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-addons) (24.2)\n",
      "Downloading tensorflow_addons-0.22.0-cp310-cp310-win_amd64.whl (719 kB)\n",
      "   ---------------------------------------- 0.0/719.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 719.8/719.8 kB 28.6 MB/s eta 0:00:00\n",
      "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.22.0 typeguard-2.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97ba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "['DTypePolicy', 'FloatDTypePolicy', 'Function', 'Initializer', 'Input', 'InputSpec', 'KerasTensor', 'Layer', 'Loss', 'Metric', 'Model', 'Operation', 'Optimizer', 'Quantizer', 'Regularizer', 'RematScope', 'Sequential', 'StatelessScope', 'SymbolicScope', 'Variable', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'activations', 'applications', 'backend', 'callbacks', 'config', 'constraints', 'datasets', 'device', 'distribution', 'dtype_policies', 'export', 'initializers', 'layers', 'legacy', 'losses', 'metrics', 'mixed_precision', 'models', 'name_scope', 'ops', 'optimizers', 'preprocessing', 'quantizers', 'random', 'regularizers', 'remat', 'tree', 'utils', 'version', 'visualization', 'wrappers']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "print(tf.__version__)\n",
    "print(dir(tf.keras))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e9807",
   "metadata": {},
   "source": [
    "## BirdCLEF 2025: ResNet-based Multi-label Classification Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741cdeec",
   "metadata": {},
   "source": [
    "In this Kaggle competition our goal is to **identify multiple animal species (primarily birds)** from 10‑second soundscape clips. We implement a deep‑learning pipeline built around an **ImageNet‑pre‑trained ResNet50** fine‑tuned on Mel‑spectrogram “images” in a **multi‑label** setting.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Data Preparation\n",
    "\n",
    "| Step | Detail (exactly mirroring the code) |\n",
    "|------|-------------------------------------|\n",
    "| **Load** | `np.load('dataset/train_data.npy', allow_pickle=True)` → dictionary with keys `data` (128 × 256 Mel) and `label` (species string). |\n",
    "| **Shape** | Each sample → `(128, 256)` **single‑channel** Mel‑spectrogram. |\n",
    "| **Label space** | Discovered dynamically from the file; in our run it equals **206 unique species** (`num_species`). |\n",
    "| **One‑Hot** | `Y_one_hot[i, idx] = 1` gives **sparse one‑hot vectors** (exactly one “1” per sample). |\n",
    "| **Stratified split** | `train_test_split(..., test_size=0.2, stratify=y_array)` → **80 / 20** train/val, preserving class ratios. |\n",
    "| **Class imbalance** | `class_weight[idx] = max_count / freq` assigns **inverse‑frequency weights** for rare species. |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Data Pipeline & Augmentation\n",
    "\n",
    "```text\n",
    "(128,256,1) Mel  ──► expand_dims\n",
    "               ──► RandomRotation(0.05)\n",
    "               ──► RandomZoom(height_factor=0.05)\n",
    "               ──► BATCH / PREFETCH\n",
    "```\n",
    "---\n",
    "\n",
    "### 3. Model Architecture\n",
    "\n",
    "| Block | Implementation |\n",
    "|-------|----------------|\n",
    "| **Input** | `Input(shape=(128,256,1))` |\n",
    "| **Channel lift** | `Conv2D(3, 1 × 1)` converts 1‑channel → 3‑channel so we can reuse ImageNet weights. |\n",
    "| **Backbone** | `ResNet50(include_top=False, weights='imagenet')` (all layers trainable by default). |\n",
    "| **Pooling** | `GlobalAveragePooling2D()` |\n",
    "| **Regularization** | `Dropout(0.3)` |\n",
    "| **Head** | `Dense(num_species, activation='sigmoid')` |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Training Configuration\n",
    "\n",
    "| Item | Code Value | Rationale |\n",
    "|------|------------|-----------|\n",
    "| **Loss** | `BinaryCrossentropy(label_smoothing=0.05)` | Multi‑label + smooth out hard 0/1 targets. |\n",
    "| **Optimizer** | `Adam(lr=1e‑4)` | Adaptive, stable for noisy gradients. |\n",
    "| **Metrics** | `AUC`, `Precision`, `Recall` | Accuracy is not informative for sparse multi‑label; these capture ranking & class‑wise performance. |\n",
    "| **Callbacks** | `ReduceLROnPlateau(factor=0.5, patience=3)` <br>`EarlyStopping(patience=5, restore_best_weights=True)` | Automatic LR scheduling and training cut‑off when val‑loss stops improving. |\n",
    "| **Epochs** | 20 (upper bound) | Early‑stop generally triggers sooner. |\n",
    "| **Class weights** | passed via `class_weight` | Boosts loss for under‑represented species. |\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Results & Persistence\n",
    "\n",
    "* After training, **best validation metrics** are restored (EarlyStopping).\n",
    "* Model is saved with `model.save('my_resnet_model_improved.h5')`, bundling architecture + weights for **one‑line re‑load**:  \n",
    "  ```python\n",
    "  model = tf.keras.models.load_model('my_resnet_model_improved.h5')\n",
    "  ```\n",
    "* Evaluation on the held‑out 20 % validation set is printed immediately after saving.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Future Work\n",
    "\n",
    "* **SpecAugment**‑style time/frequency masking could further boost robustness.  \n",
    "* Explore **EfficientNet‑based** backbones for a better parameter‑accuracy trade‑off.  \n",
    "* Iion choices, loss/metric configs, and saving paths are all one‑to‑one with the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26adc42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 28564\n",
      "Mel shape: (128,256)\n",
      "Number of unique species: 206\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 1) Load train_data.npy\n",
    "# -------------------------\n",
    "data_dict = np.load('dataset/train_data.npy', allow_pickle=True).item()\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "all_labels_set = set()\n",
    "\n",
    "for fid, content in data_dict.items():\n",
    "    mel_2d = content['data']             # shape=(128,256)\n",
    "    label_str = content['label']         # 'species_xxx'\n",
    "\n",
    "    X_list.append(mel_2d)\n",
    "    y_list.append(label_str)\n",
    "    all_labels_set.add(label_str)\n",
    "\n",
    "X_array = np.array(X_list, dtype=np.float32)    # shape=(N,128,256)\n",
    "y_array = np.array(y_list)                      # shape=(N,)\n",
    "\n",
    "all_labels = sorted(list(all_labels_set))\n",
    "label_to_idx = {lb: i for i, lb in enumerate(all_labels)}\n",
    "num_species = len(all_labels)\n",
    "\n",
    "print(\"Number of samples:\", X_array.shape[0])\n",
    "print(\"Mel shape: (128,256)\")\n",
    "print(\"Number of unique species:\", num_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fcec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (22851, 128, 256) (22851, 206)\n",
      "Val shape: (5713, 128, 256) (5713, 206)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2) Multi-label One-Hot: Only one position in each record is 1\n",
    "# -----------------------------\n",
    "Y_one_hot = np.zeros((len(y_array), num_species), dtype=np.float32)\n",
    "for i, lb in enumerate(y_array):\n",
    "    Y_one_hot[i, label_to_idx[lb]] = 1.0\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Split training/validation set (80/20)\n",
    "# -----------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_array, Y_one_hot, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_array # Stratify by string label\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Val shape:\",   X_val.shape,   y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc129c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weight example: [(110, 7.7952755905511815), (177, 6.470588235294118), (71, 3.1832797427652735), (30, 33.0), (47, 47.142857142857146)]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4) Dealing with data imbalance -> class_weight\n",
    "# -----------------------------\n",
    "label_counts = Counter(y_array)\n",
    "max_count = max(label_counts.values())\n",
    "# Give higher weight to less common categories\n",
    "class_weight = {}\n",
    "for lb, freq in label_counts.items():\n",
    "    idx = label_to_idx[lb]\n",
    "    class_weight[idx] = max_count / freq\n",
    "\n",
    "print(\"Class weight example:\", list(class_weight.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaec645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5) Build data pipeline + data augmentation\n",
    "# -----------------------------\n",
    "augment_layers = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(height_factor=0.05)\n",
    "])\n",
    "\n",
    "def preprocess_fn(x, y):\n",
    "    # x: (128,256) => expand dims(128,256,1)\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    # cast to float\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = augment_layers(x, training=True)  \n",
    "    return x, y\n",
    "\n",
    "def preprocess_fn_val(x, y):\n",
    "    # No data augmentation for validation set\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    return x, y\n",
    "\n",
    "batch_size = 16\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.shuffle(buffer_size=2048).map(preprocess_fn).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_ds = val_ds.map(preprocess_fn_val).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13687a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ResNet50_BirdCLEF\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ResNet50_BirdCLEF\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">422,094</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m206\u001b[0m)            │       \u001b[38;5;34m422,094\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,009,812</span> (91.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,009,812\u001b[0m (91.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,956,692</span> (91.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,956,692\u001b[0m (91.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6) Build ResNet (Keras)\n",
    "# - Input (128,256,1) => First use Conv2D to transform to 3 channels => ResNet50 => GAP => Multi-label sigmoid\n",
    "# - Add Dropout after ResNet output\n",
    "# - Use BinaryCrossentropy for label smoothing\n",
    "# -----------------------------\n",
    "def build_resnet50(input_shape=(128, 256, 1), num_classes=206):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(3, (1, 1), padding='same')(inputs)\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    x = base_model(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name=\"ResNet50_BirdCLEF\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_resnet50(input_shape=(128, 256, 1), num_classes=num_species)\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.05  # Smoothing\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(name='auc', multi_label=True),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Early Stop Callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5616b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1250s\u001b[0m 855ms/step - auc: 0.4705 - loss: 1.2112 - precision: 0.0044 - recall: 0.0176 - val_auc: 0.5833 - val_loss: 0.1341 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3003s\u001b[0m 2s/step - auc: 0.5557 - loss: 0.9794 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.7492 - val_loss: 0.1333 - val_precision: 0.1250 - val_recall: 7.0016e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2394s\u001b[0m 2s/step - auc: 0.6803 - loss: 0.9749 - precision: 0.0197 - recall: 2.9257e-05 - val_auc: 0.7960 - val_loss: 0.1327 - val_precision: 0.5476 - val_recall: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1611s\u001b[0m 1s/step - auc: 0.7592 - loss: 0.9593 - precision: 0.3186 - recall: 9.2242e-04 - val_auc: 0.8183 - val_loss: 0.1323 - val_precision: 0.5620 - val_recall: 0.0238 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1038s\u001b[0m 726ms/step - auc: 0.8023 - loss: 0.9621 - precision: 0.4913 - recall: 0.0042 - val_auc: 0.8293 - val_loss: 0.1320 - val_precision: 0.5613 - val_recall: 0.0264 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m968s\u001b[0m 677ms/step - auc: 0.8258 - loss: 0.9457 - precision: 0.6881 - recall: 0.0103 - val_auc: 0.8442 - val_loss: 0.1313 - val_precision: 0.5979 - val_recall: 0.0396 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m929s\u001b[0m 650ms/step - auc: 0.8431 - loss: 0.9455 - precision: 0.7879 - recall: 0.0254 - val_auc: 0.8428 - val_loss: 0.1310 - val_precision: 0.7281 - val_recall: 0.0670 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m942s\u001b[0m 659ms/step - auc: 0.8654 - loss: 0.9374 - precision: 0.7974 - recall: 0.0424 - val_auc: 0.8370 - val_loss: 0.1306 - val_precision: 0.6578 - val_recall: 0.1043 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m927s\u001b[0m 649ms/step - auc: 0.8719 - loss: 0.9296 - precision: 0.8411 - recall: 0.0722 - val_auc: 0.8536 - val_loss: 0.1303 - val_precision: 0.7096 - val_recall: 0.1147 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m909s\u001b[0m 636ms/step - auc: 0.8857 - loss: 0.9465 - precision: 0.8406 - recall: 0.0964 - val_auc: 0.8629 - val_loss: 0.1294 - val_precision: 0.7653 - val_recall: 0.1593 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m916s\u001b[0m 641ms/step - auc: 0.8873 - loss: 0.9223 - precision: 0.8811 - recall: 0.1225 - val_auc: 0.8174 - val_loss: 0.1335 - val_precision: 0.2820 - val_recall: 0.1182 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m923s\u001b[0m 646ms/step - auc: 0.8884 - loss: 0.9193 - precision: 0.8846 - recall: 0.1695 - val_auc: 0.8690 - val_loss: 0.1287 - val_precision: 0.7901 - val_recall: 0.2141 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m925s\u001b[0m 648ms/step - auc: 0.8935 - loss: 0.9213 - precision: 0.8778 - recall: 0.1859 - val_auc: 0.8561 - val_loss: 0.1291 - val_precision: 0.7816 - val_recall: 0.1967 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m935s\u001b[0m 654ms/step - auc: 0.9020 - loss: 0.9093 - precision: 0.8863 - recall: 0.2223 - val_auc: 0.8721 - val_loss: 0.1285 - val_precision: 0.7676 - val_recall: 0.2556 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m939s\u001b[0m 657ms/step - auc: 0.9045 - loss: 0.9118 - precision: 0.8929 - recall: 0.2463 - val_auc: 0.8760 - val_loss: 0.1274 - val_precision: 0.8316 - val_recall: 0.2991 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m939s\u001b[0m 657ms/step - auc: 0.9083 - loss: 0.9196 - precision: 0.8931 - recall: 0.2857 - val_auc: 0.8706 - val_loss: 0.1276 - val_precision: 0.7755 - val_recall: 0.3217 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m940s\u001b[0m 658ms/step - auc: 0.9120 - loss: 0.9149 - precision: 0.8951 - recall: 0.3042 - val_auc: 0.8500 - val_loss: 0.1290 - val_precision: 0.6400 - val_recall: 0.2657 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636ms/step - auc: 0.9086 - loss: 0.9069 - precision: 0.8905 - recall: 0.3238\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m963s\u001b[0m 674ms/step - auc: 0.9087 - loss: 0.9068 - precision: 0.8905 - recall: 0.3238 - val_auc: 0.8684 - val_loss: 0.1277 - val_precision: 0.7783 - val_recall: 0.2981 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m939s\u001b[0m 657ms/step - auc: 0.9129 - loss: 0.8962 - precision: 0.9135 - recall: 0.3817 - val_auc: 0.8756 - val_loss: 0.1275 - val_precision: 0.7655 - val_recall: 0.3543 - learning_rate: 5.0000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m1429/1429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m933s\u001b[0m 653ms/step - auc: 0.9157 - loss: 0.8879 - precision: 0.9082 - recall: 0.4237 - val_auc: 0.8828 - val_loss: 0.1266 - val_precision: 0.7959 - val_recall: 0.3898 - learning_rate: 5.0000e-05\n",
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 159ms/step - auc: 0.7709 - loss: 0.1266 - precision: 0.7917 - recall: 0.3850\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 16\u001b[0m\n\u001b[0;32m      7\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      8\u001b[0m     train_ds,\n\u001b[0;32m      9\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_ds,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[lr_scheduler, early_stopping]\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_resnet_model_improved.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m---> 16\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(val_ds, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_loss)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_acc)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 7) Start training\n",
    "# Multi-label + class_weight\n",
    "# -----------------------------\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")\n",
    "model.save('my_resnet_model_improved.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74558628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m358/358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 150ms/step - auc: 0.7709 - loss: 0.1266 - precision: 0.7917 - recall: 0.3850\n",
      "Validation Loss: 0.1266\n",
      "Validation AUC: 0.8828\n",
      "Precision: 0.7959\n",
      "Recall: 0.3898\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(val_ds, verbose=1)\n",
    "val_loss = results[0]\n",
    "val_auc = results[1]\n",
    "val_precision = results[2]\n",
    "val_recall = results[3]\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall: {val_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49349b20",
   "metadata": {},
   "source": [
    "## Training Summary of Improved\n",
    "\n",
    "### Final Validation Results\n",
    "\n",
    "| Metric       | Value    |\n",
    "|--------------|----------|\n",
    "| **Loss**     | `0.1266` |\n",
    "| **AUC**      | `0.8828` |\n",
    "| **Precision**| `0.7959` |\n",
    "| **Recall**   | `0.3898` |\n",
    "\n",
    "These results show that the model performs **very well in terms of ranking (AUC ≈ 0.88)** and **has strong precision (≈ 0.80)**, though recall is moderate due to the single-label nature of training.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparison with Baseline\n",
    "\n",
    "| Version           | AUC    | Loss   | Notes |\n",
    "|-------------------|--------|--------|-------|\n",
    "| Baseline (from scratch) | ~0.63 | ~0.13 | No pretraining, no label smoothing, used accuracy |\n",
    "| Improved (this version) | **0.88** | **0.1266** | With pretrained backbone, real metrics, regularization |\n",
    "\n",
    "The improved model demonstrates a **significant gain in AUC (~+0.25)** and a **clearer training trajectory**. These changes resulted in better generalization and more confidence-calibrated predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
