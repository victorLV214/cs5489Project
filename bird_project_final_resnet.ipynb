{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird Project Final (In Kaggle Env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T12:49:23.247346Z",
     "iopub.status.busy": "2025-04-17T12:49:23.245813Z",
     "iopub.status.idle": "2025-04-17T12:49:23.255345Z",
     "shell.execute_reply": "2025-04-17T12:49:23.254102Z",
     "shell.execute_reply.started": "2025-04-17T12:49:23.247305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "from scipy import signal\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T12:49:30.796625Z",
     "iopub.status.busy": "2025-04-17T12:49:30.796265Z",
     "iopub.status.idle": "2025-04-17T12:49:30.820950Z",
     "shell.execute_reply": "2025-04-17T12:49:30.819852Z",
     "shell.execute_reply.started": "2025-04-17T12:49:30.796599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MyAudioConfig:\n",
    "    def __init__(self):\n",
    "        # sampling\n",
    "        self.sample_rate = 32000\n",
    "        self.window_size = 5  # seconds\n",
    "\n",
    "        # mel-spec\n",
    "        self.n_fft = 2048\n",
    "        self.hop_length = 512\n",
    "        self.n_mels = 128\n",
    "        self.fmin = 20\n",
    "        self.fmax = 16000\n",
    "        self.power = 2.0\n",
    "        self.target_shape = (256, 128)\n",
    "\n",
    "        # processing\n",
    "        self.noise_reduction_strength = 0.1\n",
    "        self.contrast_factor = 0.15\n",
    "\n",
    "        # spec augment\n",
    "        self.freq_mask_param = 20\n",
    "        self.time_mask_param = 30\n",
    "        self.freq_mask_count = 1\n",
    "        self.time_mask_count = 1\n",
    "\n",
    "        self.eps = 1e-6\n",
    "\n",
    "\n",
    "class MyAudioPipeline:\n",
    "    def __init__(self, cfg: MyAudioConfig):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def reduce_noise(self, audio: np.ndarray) -> np.ndarray:\n",
    "        denoised = signal.medfilt(audio, 5)\n",
    "        a = self.cfg.noise_reduction_strength\n",
    "        return (1 - a) * audio + a * denoised\n",
    "\n",
    "    def normalize_audio(self, audio: np.ndarray) -> np.ndarray:\n",
    "        audio = audio - np.mean(audio)\n",
    "        m = np.max(np.abs(audio))\n",
    "        return audio / m if m > 0 else audio\n",
    "\n",
    "    def enhance_contrast(self, spec: np.ndarray) -> np.ndarray:\n",
    "        mu = np.mean(spec)\n",
    "        return np.clip(mu + (spec - mu) * (1 + self.cfg.contrast_factor), 0, 1)\n",
    "\n",
    "    def spec_augment(self, spec: np.ndarray) -> np.ndarray:\n",
    "        out = spec.copy()\n",
    "        # freq mask\n",
    "        for _ in range(self.cfg.freq_mask_count):\n",
    "            f = np.random.randint(0, self.cfg.freq_mask_param)\n",
    "            f0 = np.random.randint(0, out.shape[0] - f)\n",
    "            out[f0:f0 + f, :] = 0\n",
    "        # time mask\n",
    "        for _ in range(self.cfg.time_mask_count):\n",
    "            t = np.random.randint(0, self.cfg.time_mask_param)\n",
    "            t0 = np.random.randint(0, out.shape[1] - t)\n",
    "            out[:, t0:t0 + t] = 0\n",
    "        return out\n",
    "\n",
    "    def audio_to_melspec(self, audio: np.ndarray) -> np.ndarray:\n",
    "        # pad/trim\n",
    "        n_samples = self.cfg.sample_rate * self.cfg.window_size\n",
    "        if len(audio) < n_samples:\n",
    "            audio = np.pad(audio, (0, n_samples - len(audio)))\n",
    "        else:\n",
    "            audio = audio[:n_samples]\n",
    "\n",
    "        audio = self.normalize_audio(self.reduce_noise(audio))\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(\n",
    "            y=audio,\n",
    "            sr=self.cfg.sample_rate,\n",
    "            n_fft=self.cfg.n_fft,\n",
    "            hop_length=self.cfg.hop_length,\n",
    "            n_mels=self.cfg.n_mels,\n",
    "            fmin=self.cfg.fmin,\n",
    "            fmax=self.cfg.fmax,\n",
    "            power=self.cfg.power,\n",
    "        )\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + self.cfg.eps)\n",
    "\n",
    "        mel_norm = self.enhance_contrast(mel_norm)\n",
    "        mel_norm = self.spec_augment(mel_norm)\n",
    "\n",
    "        if self.cfg.target_shape:\n",
    "            mel_norm = cv2.resize(mel_norm, self.cfg.target_shape, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        return mel_norm.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T12:49:36.210264Z",
     "iopub.status.busy": "2025-04-17T12:49:36.209924Z",
     "iopub.status.idle": "2025-04-17T12:53:18.499364Z",
     "shell.execute_reply": "2025-04-17T12:53:18.497471Z",
     "shell.execute_reply.started": "2025-04-17T12:49:36.210242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"/kaggle/input/birdclef-2025/sample_submission.csv\")\n",
    "species_columns = list(sample.columns[1:])\n",
    "NUM_SPECIES = len(species_columns)\n",
    "\n",
    "model = tf.keras.models.load_model(\"/kaggle/input/my_resnet_model_improved/keras/default/1/my_resnet_model_improved.h5\")\n",
    "\n",
    "cfg = MyAudioConfig()\n",
    "pipeline = MyAudioPipeline(cfg)\n",
    "TEST_DIR = \"/kaggle/input/birdclef-2025/test_soundscapes\"\n",
    "WIN_SEC  = cfg.window_size\n",
    "WIN_SAMPLES = cfg.sample_rate * WIN_SEC\n",
    "\n",
    "rows = []\n",
    "ogg_list = sorted(glob.glob(os.path.join(TEST_DIR, \"*.ogg\")))\n",
    "print(\"Total number of test audio files found: \", len(ogg_list))\n",
    "\n",
    "for ogg in tqdm(ogg_list):\n",
    "    y, _ = librosa.load(ogg, sr=cfg.sample_rate, mono=True)\n",
    "    n_windows = len(y) // WIN_SAMPLES\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(ogg))[0]\n",
    "\n",
    "    for k in range(n_windows):\n",
    "        seg = y[k*WIN_SAMPLES : (k+1)*WIN_SAMPLES]\n",
    "        mel = pipeline.audio_to_melspec(seg)            # (128,256)\n",
    "        mel = np.expand_dims(mel, axis=(0,-1))          # (1,128,256,1)\n",
    "\n",
    "        probs = model.predict(mel, verbose=0)[0]        # (206,)\n",
    "\n",
    "        row_id = f\"{base}_{(k+1)*WIN_SEC}\"\n",
    "        rows.append([row_id, *probs])\n",
    "        \n",
    "\n",
    "sub_df = pd.DataFrame(rows, columns=[\"row_id\"] + species_columns)\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv saved\", sub_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "isSourceIdPinned": false,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 307313,
     "modelInstanceId": 286485,
     "sourceId": 342462,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
